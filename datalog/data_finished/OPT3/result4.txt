比例:生成0.68,开源0.32 模型 CNN 验证集 小样本
Test Loss:  0.029, Test Acc:  98.72%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       fraud       1.00      0.97      0.99       156
      normal       0.97      1.00      0.99       156

    accuracy                           0.99       312
   macro avg       0.99      0.99      0.99       312
weighted avg       0.99      0.99      0.99       312
比例:生成0.68,开源0.32 模型 CNN 验证集 开源测试集
Test Loss:    1.2, Test Acc:  70.09%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       fraud       0.98      0.41      0.58       107
      normal       0.63      0.99      0.77       107

    accuracy                           0.70       214
   macro avg       0.80      0.70      0.67       214
weighted avg       0.80      0.70      0.67       214
比例:生成0.68,开源0.32 模型 gru 验证集 开源测试集
Test Loss:    2.2, Test Acc:  57.94%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       fraud       1.00      0.16      0.27       107
      normal       0.54      1.00      0.70       107

    accuracy                           0.58       214
   macro avg       0.77      0.58      0.49       214
weighted avg       0.77      0.58      0.49       214
比例:生成0.68,开源0.32 模型 gru 验证集 小样本
Test Loss:   0.16, Test Acc:  95.83%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       fraud       1.00      0.92      0.96       156
      normal       0.92      1.00      0.96       156

    accuracy                           0.96       312
   macro avg       0.96      0.96      0.96       312
weighted avg       0.96      0.96      0.96       312
比例:生成0.68,开源0.32 模型 lstm 验证集 开源测试集
Test Loss:    2.7, Test Acc:  57.01%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       fraud       1.00      0.14      0.25       107
      normal       0.54      1.00      0.70       107

    accuracy                           0.57       214
   macro avg       0.77      0.57      0.47       214
weighted avg       0.77      0.57      0.47       214
比例:生成0.68,开源0.32 模型 lstm 验证集 小样本
Test Loss:   0.23, Test Acc:  95.51%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       fraud       1.00      0.91      0.95       156
      normal       0.92      1.00      0.96       156

    accuracy                           0.96       312
   macro avg       0.96      0.96      0.96       312
weighted avg       0.96      0.96      0.96       312